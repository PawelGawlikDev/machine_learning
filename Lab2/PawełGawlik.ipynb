{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.keys()\n",
    "print(mnist.data.shape)\n",
    "print(mnist.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_img, test_img, train_lbl, test_lbl = train_test_split(\n",
    "\n",
    "\n",
    "    mnist.data, mnist.target, test_size=0.3, random_state=0, stratify=mnist.target)\n",
    "\n",
    "print(train_img.shape)\n",
    "\n",
    "# Valid split\n",
    "test_img, val_img, test_lbl, val_lbl = train_test_split(\n",
    "    test_img, test_lbl, test_size=0.5, random_state=0, stratify=test_lbl)\n",
    "\n",
    "class_counts = np.bincount(val_lbl.astype(int))\n",
    "\n",
    "for class_id, count in enumerate(class_counts):\n",
    "    print(f\"Klasa {class_id}: {count} wzorcÃ³w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example data\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "\n",
    "for index, (image, label) in enumerate(zip(train_img[0:5], train_lbl[0:5])):\n",
    "\n",
    "\n",
    "    plt.subplot(1, 5, index+1)\n",
    "\n",
    "    plt.imshow(np.reshape(image, (28, 28)), cmap=plt.cm.gray)\n",
    "\n",
    "    plt.title('Training: %s\\n' % label, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "clf = MLPClassifier()\n",
    "\n",
    "clf.fit(train_img, train_lbl)\n",
    "predictions = clf.predict(test_img)\n",
    "# Loss function plot\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Value of the loss function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts\n",
    "predictions_train = clf.predict(train_img)\n",
    "\n",
    "predictions_test = clf.predict(test_img)\n",
    "\n",
    "train_score = accuracy_score(predictions_train, train_lbl)\n",
    "\n",
    "\n",
    "print('Score on train data: ', train_score)\n",
    "\n",
    "test_score = accuracy_score(predictions_test, test_lbl)\n",
    "\n",
    "\n",
    "print('Score on train data: ', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five error predictions\n",
    "index = 0\n",
    "\n",
    "badIndex = 0\n",
    "\n",
    "misclassifiedIndexes = []\n",
    "\n",
    "\n",
    "for label, predict in zip(test_lbl, predictions):\n",
    "    badIndex = badIndex+1\n",
    "    if label != predict:\n",
    "        misclassifiedIndexes.append(badIndex)\n",
    "        print(misclassifiedIndexes[index], label,\n",
    "\n",
    "              test_lbl[badIndex - 1], predict, predictions[badIndex - 1])\n",
    "        index += 1\n",
    "\n",
    "print(test_lbl[4], predictions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error predictions\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "\n",
    "for plotIndex, badIndex, in enumerate(misclassifiedIndexes[0:5]):\n",
    "    print(badIndex, predictions[badIndex - 1], test_lbl[badIndex - 1])\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(test_img[badIndex-1], (28, 28)), cmap=plt.cm.gray)\n",
    "\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(\n",
    "\n",
    "        predictions[badIndex - 1], test_lbl[badIndex-1]), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matri\n",
    "ConfusionMatrixDisplay.from_predictions(predictions_test, test_lbl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd solver\n",
    "clf = MLPClassifier(solver='sgd')\n",
    "\n",
    "clf.fit(train_img, train_lbl)\n",
    "predictions = clf.predict(test_img)\n",
    "score = accuracy_score(predictions, test_lbl)\n",
    "print('sdg score: ', score)\n",
    "# Loss function plot\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.title('Loss Curve fro sgd solver')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Value of the loss function')\n",
    "ConfusionMatrixDisplay.from_predictions(predictions, test_lbl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different neurons neurons\n",
    "hidden_layer_sizes = [(50,), (100,), (50, 50), (100, 100)]\n",
    "for h_layer_size in hidden_layer_sizes:\n",
    "    clf = MLPClassifier(hidden_layer_sizes=h_layer_size)\n",
    "\n",
    "    clf.fit(train_img, train_lbl)\n",
    "    predictions = clf.predict(test_img)\n",
    "    score = accuracy_score(predictions, test_lbl)\n",
    "    print(f'{h_layer_size} score: ', score)\n",
    "    # Loss function plot\n",
    "    plt.plot(clf.loss_curve_)\n",
    "    plt.title(f'Loss Curve for {h_layer_size}')\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Value of the loss function')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable momentum\n",
    "clf = MLPClassifier(momentum=0)\n",
    "\n",
    "clf.fit(train_img, train_lbl)\n",
    "predictions = clf.predict(test_img)\n",
    "score = accuracy_score(predictions, test_lbl)\n",
    "print('Disable momentum score: ', score)\n",
    "# Loss function plot\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.title('Loss Curve for disable momentum')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Value of the loss function')\n",
    "ConfusionMatrixDisplay.from_predictions(predictions, test_lbl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max iteration\n",
    "iteration = [10, 50, 500]\n",
    "for max_i in iteration:\n",
    "    clf = MLPClassifier(max_iter=max_i)\n",
    "\n",
    "    clf.fit(train_img, train_lbl)\n",
    "    predictions = clf.predict(test_img)\n",
    "    score = accuracy_score(predictions, test_lbl)\n",
    "    print(f'{max_i} score: ', score)\n",
    "    # Loss function plot\n",
    "    plt.plot(clf.loss_curve_)\n",
    "    plt.title(f'Loss Curve for {max_i}')\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Value of the loss function')\n",
    "    ConfusionMatrixDisplay.from_predictions(predictions, test_lbl)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping\n",
    "clf = MLPClassifier(early_stopping=True)\n",
    "\n",
    "clf.fit(train_img, train_lbl)\n",
    "predictions = clf.predict(test_img)\n",
    "score = accuracy_score(predictions, test_lbl)\n",
    "print('Early stopping score: ', score)\n",
    "# Loss function plot\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.title('Loss Curve for enable early_stopping')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Value of the loss function')\n",
    "ConfusionMatrixDisplay.from_predictions(predictions, test_lbl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different activaction\n",
    "clf = MLPClassifier(activation='logistic')\n",
    "\n",
    "clf.fit(train_img, train_lbl)\n",
    "predictions = clf.predict(test_img)\n",
    "score = accuracy_score(predictions, test_lbl)\n",
    "print('sigmoidal activation score: ', score)\n",
    "# Loss function plot\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.title('Loss Curve for logistic activation')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Value of the loss function')\n",
    "ConfusionMatrixDisplay.from_predictions(predictions, test_lbl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypoparameters to test\n",
    "hidden_layer_sizes = [(50,), (100,), (50, 50), (100, 100)]\n",
    "activation = ['identity', 'relu', 'tanh', 'logistic']\n",
    "alpha = [0.00001, 0.0001, 0.001, 0.01]\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "best_score = 0\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h_layer_size in hidden_layer_sizes:\n",
    "    for act in activation:\n",
    "        for alpha_val in alpha:\n",
    "            for s in solvers:\n",
    "                clf = MLPClassifier(hidden_layer_sizes=h_layer_size,\n",
    "                                    activation=act, alpha=alpha_val, solver=s)\n",
    "                clf.fit(train_img, train_lbl)\n",
    "                predictions_val = clf.predict(val_img)\n",
    "                val_score = accuracy_score(predictions_val, val_lbl)\n",
    "                if val_score > best_score:\n",
    "                    best_score = val_score\n",
    "                    best_params = {'hidden_layer_sizes': h_layer_size,\n",
    "                                   'activation': act, 'alpha': alpha_val, 'solver': s}\n",
    "\n",
    "print(\"Best scores: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with the best params\n",
    "final_clf = MLPClassifier(**best_params)\n",
    "final_clf.fit(np.concatenate((train_img, val_img)),\n",
    "              np.concatenate((train_lbl, val_lbl)))\n",
    "final_prediction = final_clf.predict(val_img)\n",
    "final_score = accuracy_score(final_prediction, val_lbl)\n",
    "print('Final score: ', final_score)\n",
    "plt.plot(final_clf.loss_curve_)\n",
    "plt.title('Loss Curve for enable early_stopping')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Value of the loss function')\n",
    "ConfusionMatrixDisplay.from_predictions(final_prediction, val_lbl)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
